# ðŸ§  vaskesh â€” AI-Powered Terminal

`vaskesh` is a custom-built Linux shell (like `bash` or `zsh`) that integrates AI command interpretation.  
You can type natural language commands like **"list all files"** or **"print working directory"**, and vaskesh will interpret and execute them automatically using an integrated AI model (via Ollama).

---

## ðŸš€ Features

- ðŸ§© Built-in command parsing and execution engine  
- ðŸ§  AI-powered natural language command interpretation  
- ðŸ§µ Background job management (run commands with `&`)  
- ðŸ“œ Command history support (using GNU `readline`)  
- ðŸ”§ Easily extendable command handlers  
- ðŸ§¹ Signal handling for clean job termination  

---

## ðŸ—‚ï¸ Project Structure

vaskesh/
â”œâ”€â”€ include/
â”‚ â”œâ”€â”€ ai_requests.h # Handles AI request logic
â”‚ â”œâ”€â”€ executor.h # Command execution functions
â”‚ â”œâ”€â”€ jobs.h # Background job management
â”‚ â”œâ”€â”€ parser.h # Input parsing and tokenization
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.c # Entry point of the shell
â”‚ â”œâ”€â”€ ai_requests.c # AI communication with Ollama
â”‚ â”œâ”€â”€ executor.c # Built-in and system command executor
â”‚ â”œâ”€â”€ jobs.c # Background/foreground job control
â”‚ â”œâ”€â”€ parser.c # Command parsing logic
â”‚
â”œâ”€â”€ Makefile # Build configuration
â”œâ”€â”€ .myshell_history # Command history file (auto-created)
â””â”€â”€ README.md # Project documentation

yaml
Copy code

---

## ðŸ§° Requirements

Before building, ensure the following dependencies are installed:

### For Linux:
```bash
sudo apt install build-essential libreadline-dev libcurl4-openssl-dev
For macOS (using Homebrew):
bash
brew install readline curl
Youâ€™ll also need Ollama installed and running:

bash
brew install --cask ollama
ollama run llama3
ðŸ—ï¸ Build Instructions
Compile the project using make:

bash
Copy code
make
This will produce an executable called myshell.

If you make changes to the source files, simply run:

bash
Copy code
make clean && make
â–¶ï¸ Running vaskesh
To start the shell:

bash
Copy code
./myshell
Youâ€™ll see a prompt like this:

shell
Copy code
vaskesh>
You can now:

Type normal shell commands like ls, pwd, cat file.txt

Or type natural language commands like:

show me files

print working directory

list all processes

vaskesh will send these natural commands to the AI model, interpret the response (e.g., pwd), and execute it.


vaskesh> list files in current folder
main.c  parser.c  jobs.c  README.md

vaskesh> sleep 10 &
[1] 12345
vaskesh>
ðŸ§  AI Integration Details
The AI interface is handled in ai_requests.c, which sends requests to the Ollama local model API via libcurl.
You can configure which model to use (e.g., llama3:latest) directly in the code.

Example of a raw Ollama response:

json
Copy code
{"model":"llama3:latest","created_at":"...","response":"pwd","done":false}
{"model":"llama3:latest","created_at":"...","response":"","done":true}
The shell captures the "response" text, logs it for visibility, and executes it as a command.

ðŸ§¹ Cleaning Up
To remove the compiled binary and temporary files:

bash
Copy code
make clean
ðŸ“„ License
This project is open-source and free to modify for personal or educational purposes.

âœ¨ Author
Emmanuel Hateka 
Focused on high-performance, detail-oriented software engineering.